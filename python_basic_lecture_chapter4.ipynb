{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Basic Lecture\n",
    "## Chapter 2: Autograd: automatic differentiation\n",
    "\n",
    "이전 시간에 배운 Tensor, 즉 배열 기반의 데이터들에 대해서 자동으로 미분을 해주는 패키지가 바로 Autograd 패키지 입니다.\n",
    "이 패키지의 경우 Define-by-run 구조를 가지는 패키지이며, 코드가 실행되면서 계속해서 미분하거나 parameter update하는 구조가 새로 정의된다는 것입니다. 반대의 경우인 Define-and-run 구조의 경우 코드가 실행되기 전에 먼저 구조를 정의한 이후에 실행되기 때문에, 구조가 변하는 데이터의 경우 다루기 힘들다는 단점이 있습니다. 이정도만 즉, Autograd는 Define-by-run이라는 사실만 이해한 이후 아래 예시를 통해 자세히 알아봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch 패키지를 import한 이후, torch.ones를 이용하여 x라는 tensor타입 2x2 배열을 만듭니다. 이 때, autograd를 쓰기 위하여 requires_grad=True로 설정해줍니다. 이를 통해서 이x라는 배열이 이후에 어떤 연산과정을 통하여 최종적으로 output을 만들게 되더라도, 그 연산과정들을 다 기록하였다가, 그를 활용하여 autograd패키지에서 gradient를 연산해주게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x라는 배열에 덧셈 연산을 한 번 시행하였으며, 출력값을 통해 연산과정이 기록되고 있다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward>)\n",
      "tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적으로 out이라는 스칼라값을 하나 얻을 수 있었으며, 최종 값이 스칼라인 경우 다른 추가 설정 없이 .backward()를 통해 gradient를 계산할 수 있으며, 그 이외의 경우에는 어떤 방식으로 gradient를 계산할 것인지 설정해주어야 합니다. 이번 예제의 경우 out이 스칼라이므로 그냥 .backward()를 통해 계산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x에서부터out까지의 연산과정을 고려한 out의 x에 대한 gradient를 구할 수 있었습니다. 구체적인 연산과정을 아래와 같습니다.\n",
    "\n",
    "You should have got a matrix of ``4.5``. Let’s call the ``out``\n",
    "*Tensor* “$o$”.\n",
    "We have that $o = \\frac{1}{4}\\sum_i z_i$,\n",
    "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
    "Therefore,\n",
    "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence\n",
    "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지를 통해 pytorch 내에서 gradient를 계산 할 때 어떤 방식으로 계산하는 지 내부를 조금 들여다봤습니다. 여기까지 배운 내용들과 이후에 딥러닝 시간에 배우는 내용들을 토대로 pytorch를 활용한 러닝기법 사용하기를 추후에 하게 될 것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
